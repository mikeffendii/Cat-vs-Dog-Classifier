{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aebd56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d038167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\M I K E/.cache\\torch\\hub\\pytorch_vision_main\n",
      "C:\\Users\\M I K E\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\M I K E\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in C:\\Users\\M I K E/.cache\\torch\\hub\\pytorch_vision_main\n",
      "C:\\Users\\M I K E\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "model_resnet34 = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f6f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all params except the BatchNorm layers, as here they are trained to the\n",
    "# mean and standard deviation of ImageNet and we may lose some signal\n",
    "for name, param in model_resnet18.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n",
    "        \n",
    "for name, param in model_resnet34.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22eb139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the classifier\n",
    "num_classes = 2\n",
    "\n",
    "model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))\n",
    "\n",
    "model_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0b4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "                        \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, accuracy = {:.4f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f690467",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "img_dimensions = 224\n",
    "\n",
    "# Normalize to the ImageNet mean and standard deviation\n",
    "# Could calculate it for the cats/dogs data set, but the ImageNet\n",
    "# values give acceptable results here.\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "img_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions,img_dimensions)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "train_data_path = \"./train/\"\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=img_transforms, is_valid_file=check_image)\n",
    "\n",
    "validation_data_path = \"./validation/\"\n",
    "validation_data = torchvision.datasets.ImageFolder(root=validation_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "\n",
    "test_data_path = \"./test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "\n",
    "num_workers = 6\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395411ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images: 2000\n",
      "Num validation images: 1000\n",
      "Num test images: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Num training images: {len(train_data_loader.dataset)}')\n",
    "print(f'Num validation images: {len(validation_data_loader.dataset)}')\n",
    "print(f'Num test images: {len(test_data_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb3982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('correct: {:d}  total: {:d}'.format(correct, total))\n",
    "    print('accuracy = {:f}'.format(correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076d6cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.1799, Validation Loss: 0.1468, accuracy = 0.9420\n",
      "Epoch: 1, Training Loss: 0.0680, Validation Loss: 0.0582, accuracy = 0.9760\n"
     ]
    }
   ],
   "source": [
    "model_resnet18.to(device)\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\n",
    "train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4f05ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 981  total: 1000\n",
      "accuracy = 0.981000\n"
     ]
    }
   ],
   "source": [
    "test_model(model_resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cef91d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.1519, Validation Loss: 0.0310, accuracy = 0.9850\n",
      "Epoch: 1, Training Loss: 0.0309, Validation Loss: 0.0319, accuracy = 0.9870\n"
     ]
    }
   ],
   "source": [
    "model_resnet34.to(device)\n",
    "optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)\n",
    "train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ee34a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 984  total: 1000\n",
      "accuracy = 0.984000\n"
     ]
    }
   ],
   "source": [
    "test_model(model_resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6437fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "def make_prediction(model, filename):\n",
    "    labels, _ = find_classes('./test')\n",
    "    img = Image.open(filename)\n",
    "    img = img_test_transforms(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    prediction = model(img.to(device))\n",
    "    prediction = prediction.argmax()\n",
    "    print(labels[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28a371d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs\n",
      "cats\n"
     ]
    }
   ],
   "source": [
    "make_prediction(model_resnet34, './test/dogs/dog.1526.jpg')\n",
    "make_prediction(model_resnet34, './test/cats/cat.1526.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bcd080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
